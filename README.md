# Anuvadak-Sign-language-to-text-convertor
## ABSTRACT
People affected by speech impairment can't communicate using hearing
and speech, they rely on sign language for communication. Sign
language is used among everybody who is speech impaired, but they
find a hard time communicating with people which are nonsigners
(people aren’t proficient in sign language). So requirement of a sign
language interpreter is a must for speech impaired people. This makes
their informal and formal communication difficult. There has been
favorable progress in the field of gesture recognition and motion
recognition with current advancements in deep learning. The proposed
system tries to do a real time translation of hand gestures into equivalent
English text. This system takes hand gestures as input through video
and translates it text which could be understood by a non-signer. There
were similar researches done earlier with most of them focussing on just
sign translation of English alphabets or just numbers. There will be use
of CNN for classification of hand gestures. By deploying this system, the
communication gap between signers and non-signers. This will make
communication speech impaired people less cumbersome. There were
many researches which helped us to establish the idea of Artificial
Neural Networks for this project. Many models were available that
detected only characters with an accuracy of around 86%. We also
explored the Linear discriminant analysis(LDA) technique but didn’t use
it due its drawback to express complex data. The hardware
implementation of the project was also read about. It has a cost and
maintenence factor involved which we tried to eliminate in our project.
We have achieved high acccuracy of 96.5% in our model, with the
feature of suggestions of words and formation of sentences, an idea
which was not found in any of the researches.
